{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7204399b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94a59e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph,START, END\n",
    "from typing import TypedDict, Literal, Annotated\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec785c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_llm = ChatOpenAI(model = \"gpt-4o\")\n",
    "evaluator_llm = ChatOpenAI(model = \"gpt-4o-mini\")\n",
    "optimizer_llm = ChatOpenAI(model = \"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66ca42f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State\n",
    "class TweetState(TypedDict):\n",
    "    topic : str \n",
    "    tweet : str \n",
    "    evaluation : Literal[\"approved\",\"needs_improvement\"]\n",
    "    iteration : int \n",
    "    max_iteration : int "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "369b79a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state\n",
    "class TweetState(TypedDict):\n",
    "\n",
    "    topic: str\n",
    "    tweet: str\n",
    "    evaluation: Literal[\"approved\", \"needs_improvement\"]\n",
    "    feedback: str\n",
    "    iteration: int\n",
    "    max_iteration: int\n",
    "\n",
    "    tweet_history: Annotated[list[str], operator.add]\n",
    "    feedback_history: Annotated[list[str], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e39ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class TweetEvaluation(BaseModel):\n",
    "    evaluation: Literal[\"approved\", \"needs_improvement\"] = Field(..., description=\"Final evaluation result.\")\n",
    "    feedback: str = Field(..., description=\"feedback for the tweet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de178494",
   "metadata": {},
   "outputs": [],
   "source": [
    "#structured Evaluator LLM \n",
    "structured_evaluator_llm = evaluator_llm.with_structured_output(TweetEvaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "305eb81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tweet(state: TweetState):\n",
    "\n",
    "    # prompt\n",
    "    messages = [\n",
    "        SystemMessage(content = \"You are a funny and clever Twitter/X influencer.\"),\n",
    "        HumanMessage(content = f\"\"\"\n",
    "Write a short, original, and hilarious tweet on the topic: \"{state['topic']}\".\n",
    "\n",
    "Rules:\n",
    "    - Do NOT use question-answer format.\n",
    "    - Max 280 characters.\n",
    "    - Use observational humor, irony, sarcasm, or cultural references.\n",
    "    - Think in meme logic, punchlines, or relatable takes.\n",
    "    - Use simple, day to day english\n",
    "    \"\"\")\n",
    "        ]\n",
    "\n",
    "    # send generator_llm\n",
    "    response = generator_llm.invoke(messages).content\n",
    "\n",
    "    # return response\n",
    "    return {'tweet': response, 'tweet_history': [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553474a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_tweet(state: TweetState):\n",
    "\n",
    "    # prompt\n",
    "    messages = [\n",
    "    SystemMessage(content = \"You are a ruthless, no-laugh-given Twitter critic. You evaluate tweets based on humor, originality, virality, and tweet format.\"),\n",
    "    HumanMessage(content = f\"\"\"\n",
    "    Evaluate the following tweet:\n",
    "\n",
    "    Tweet: \"{state['tweet']}\"\n",
    "\n",
    "    Use the criteria below to evaluate the tweet:\n",
    "\n",
    "    1. Originality – Is this fresh, or have you seen it a hundred times before?  \n",
    "    2. Humor – Did it genuinely make you smile, laugh, or chuckle?  \n",
    "    3. Punchiness – Is it short, sharp, and scroll-stopping?  \n",
    "    4. Virality Potential – Would people retweet or share it?  \n",
    "    5. Format – Is it a well-formed tweet (not a setup-punchline joke, not a Q&A joke, and under 280 characters)?\n",
    "\n",
    "    Auto-reject if:\n",
    "    - It's written in question-answer format (e.g., \"Why did...\" or \"What happens when...\")\n",
    "    - It exceeds 280 characters\n",
    "    - It reads like a traditional setup-punchline joke\n",
    "    - Dont end with generic, throwaway, or deflating lines that weaken the humor (e.g., “Masterpieces of the auntie-uncle universe” or vague summaries)\n",
    "\n",
    "    ### Respond ONLY in structured format:\n",
    "    - evaluation: \"approved\" or \"needs_improvement\"  \n",
    "    - feedback: One paragraph explaining the strengths and weaknesses \n",
    "    \"\"\")\n",
    "    ]\n",
    "\n",
    "    response = structured_evaluator_llm.invoke(messages)\n",
    "\n",
    "    return {'evaluation':response.evaluation, 'feedback': response.feedback, 'feedback_history': [response.feedback]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65da82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_tweet(state: TweetState):\n",
    "    messages = [\n",
    "        SystemMessage(content = \"You punch up tweets for virality and humor based on given feedback.\"),\n",
    "        HumanMessage(content = f\"\"\"\n",
    "    Improve the tweet based on this feedback: \"{state['feedback']}\"\n",
    "    Topic: \"{state['topic']}\"\n",
    "    Original Tweet: {state['tweet']}\n",
    "\n",
    "    Re-write it as a short, viral-worthy tweet. Avoid Q&A style and stay under 280 characters.\n",
    "    \"\"\")\n",
    "        ]\n",
    "\n",
    "    response = optimizer_llm.invoke(messages).content\n",
    "    iteration = state['iteration'] + 1\n",
    "\n",
    "    return {'tweet': response, 'iteration': iteration, 'tweet_history': [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe51cd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_evaluation(state: TweetState):\n",
    "    if state['evaluation'] == 'approved' or state['iteration'] >= state['max_iteration']:\n",
    "        return 'approved'\n",
    "    else:\n",
    "        return 'needs_improvement'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c136578",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimizer_tweet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m graph.add_node(\u001b[33m'\u001b[39m\u001b[33mgenerate\u001b[39m\u001b[33m'\u001b[39m,generate_tweet)\n\u001b[32m      6\u001b[39m graph.add_node(\u001b[33m'\u001b[39m\u001b[33mevaluate\u001b[39m\u001b[33m'\u001b[39m,evaluate_tweet)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m graph.add_edge(\u001b[33m'\u001b[39m\u001b[33moptimize\u001b[39m\u001b[33m'\u001b[39m,\u001b[43moptimizer_tweet\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'optimizer_tweet' is not defined"
     ]
    }
   ],
   "source": [
    "# StateGraph \n",
    "graph = StateGraph(TweetState)\n",
    "\n",
    "#Add the Nodes \n",
    "graph.add_node('generate',generate_tweet)\n",
    "graph.add_node('evaluate',evaluate_tweet)\n",
    "graph.add_edge('optimize',optimizer_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13ad021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d2fa6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "U_agentic_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
