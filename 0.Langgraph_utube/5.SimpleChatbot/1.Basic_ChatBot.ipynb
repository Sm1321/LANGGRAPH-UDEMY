{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac156478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cccd6e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict, Annotated\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.memory import MemorySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f5d2b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph.message import add_messages\n",
    "#add messages is the reducer functions to add all the messages\n",
    "class ChatState(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "025b2cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI()\n",
    "\n",
    "\n",
    "def chat_node(state : ChatState):\n",
    "    #Take the user Query\n",
    "    messages = state['messages']\n",
    "\n",
    "\n",
    "    #Send the llm\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "\n",
    "    # Responde store State\n",
    "    return {'messages':[response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf850de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = MemorySaver()\n",
    "\n",
    "graph = StateGraph(ChatState)\n",
    "\n",
    "#Add Nodes\n",
    "graph.add_node('chat_node',chat_node)\n",
    "\n",
    "#Add the Edge\n",
    "graph.add_edge(START,'chat_node')\n",
    "graph.add_edge('chat_node',END)\n",
    "\n",
    "chatbot = graph.compile(checkpointer = checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84af650d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHkAAADqCAIAAAAJan3zAAAAAXNSR0IArs4c6QAAFz1JREFUeJztnWlcFEfegGt6eph7gGFmGC45gxcIERQ1riYeSXRVxNeDbHSzml2NxgNfE6NuXA2JMbvibgybqGiiQbOr8QKP9SCvN3jgwaUYFQS5BYa57555P4w/4poB7Z6egsF6fn6Qrq7uv49FdXVVdRXDbrcDBBSwrg7gBQK5hgdyDQ/kGh7INTyQa3jg7rio1WJ7VGPSawi92koQdovJA5qVbC6Gsxg8Ic4VMuWhHHfcgk7XRj1x97qmslTXWG2QBnF4QiZPhIskLOAJTXi7DTQ9NOk1OhzHqst1YTH8yFh+VLyQxlsw6HqXuXSs9eHPenkoJyKWHxLNo+WaXYXZZKsq01Xd0dX+bBg20a/PIBEtl6XB9d0bmrwfmpLeFCeOFdMSU/dBp7YWHGlVtVhen+UvErNcvJqrrvMPt1gttt9MlmJMhouhdFvaHpkOb2kYMUUaHsN35Touub6Y28ITMgeO8nUlAk/h6Pb6gaN8AyO4lK9Avc13fEcDh4+9IKIBABP+GHj9p7Zbl1WUr0DR9dWTCrHcK3FMT6ugO2fi3MBbl9RN1UZq2am4fnBLZ9ITSeP8qN3So5m+NKTgWKvFZKOQl4rr8wea40b6UMjYM3gpTnDxcAuFjKRdl+WrevXlud4A8lxiXvF+WK5XKyxkM5J2XVGqHT5JQjZXD2PEFEnJedIPSXKua+/pbQRgsV/0HqteffklF5Rkc5GzVlmqi4h1qT1PgRUrVuTm5lLIOHbs2Lq6OjdEBJhMRnA0r7pcRyoXOdeKRnPkANiub9++TSFXQ0NDW1ubG8J5TPRAQe19PaksJN4bCcK+dXnFgo1RlGJ7Nvn5+dnZ2bdu3ZJIJHFxcYsWLZJIJImJiY5UgUBw9uxZrVa7e/fuS5cuVVRUSCSSkSNHzp8/n8PhAACWL1/OZDIDAgKys7PnzZu3detWR8aRI0du3LiR9mhr7+kLT7WlvB9EIo/9uVErzDvWPnj+80lRXl6ekJCwbdu2hoaG/Pz81NTU999/3263G43GhISEnJwcx2nbtm1LSkrKy8srLCw8ffr0uHHjNm3a5EhatWrV1KlTFy1adO7cOYVCceHChYSEhNraWjcFrGg07fq8ilQWEv3Xeg3BEzKplIHnoKioiMPhzJkzB8MwuVzer1+/+/fv//q0mTNnjh49Ojw83PFjcXFxQUHB4sWLAQAMBqO+vn7Xrl2OYu5u+N64TmUllYWEa5vVzuG7qwUSHx9vNBrT0tKSkpJGjBgREhLSXns8CYvFunTp0po1a+7evWu1WgEAYvEv/QTh4eFwRAMAMAywueRKHgl3PG9c+Yh0A/456dOnz1dffSWVSjMzM1NSUhYsWFBcXPzr0zIzM7OyslJSUnJycq5duzZ79uwnU9lstpvC+zU6NYGR/CUn41rI1GsI0kE9N8OGDVu9evWRI0fWrl2rUqnS0tIcJbcdu91+4MCBGTNmpKSkyOVyAIBGo3FfPJ2jU1v5InIjiCRcs7ywgAiO0eAW3devXy8oKAAASKXSCRMmLFu2TKPRNDQ0PHmOxWIxGAwymczxo9lsPn/+vDuCeR6MOoLsEDC5+pcvwh+UkmvAPyfFxcXLly8/ePBgW1tbWVnZnj17pFJpQEAAm82WyWSXL1++du0ahmFhYWGHDx+ura1VKpXp6enx8fFqtVqncxJSWFgYACAvL6+srMwdAd+9oZX1IldlkXMdEcuvdI/rmTNnpqSkZGRkjB07du7cuXw+PysrC8dxAMCcOXMKCwuXLVtmMBg+//xzDoczderUyZMnDx48eOHChRwOZ8yYMfX19U9dMDg4eOLEiVu2bMnMzHRHwA/KdGSHxMiNgdls9pyv66YsCiYfW4+i7r7+5+uaUTP8SeUiV64xjBEUxb16UkEytp5GwdHWfkneZHORnouTNM5v84cVA0f54Czn/0+jRo2y2ZwMWxAEgWEYg+F8uD0nJ8fHxy3jD0VFRWlpaU6TzGYzi8VyGlJERMR3333nNFdlqZYnxOVhpBvyVMbRb11WGTRER7NBqLXDhEI6Zxg9RUchmUymjprkDAZDIBA4TTq+s2HoeD8fmRfZMCjOWcjb3RTSh9snkZ4JQR7EyV2N4f340QlUSgbFd+6xM/1vnlHW3iPXqejpXMhpFvrg1ES7Ohcn55u6+Fd9wvrB7tHuEi7mtvhIWTHDSD8S23GpL2nygqDSi6pi8qNBHsfRbfUcHuaKaHrmTl49obh7QzNsol9ErPOHiUdz43Rb0Tnla9Nl4f1d/fWlZ05w2yNzwZFWjAlConnhMXyynTLdkJZ6U/Vt/c0zbX2TREMn+GEYDTNDaZt/DQBoeGC4U6h5UKYTinFJEFvgjfNETIE3iyA8YK47A2NoFGadirDZ7Pdvar04WGQcP3a4D5dP2/AIna7baXpoaK4xa1VWvZrAcKBT0dk1aDKZ7t27FxMTQ+M1AQBCMW4nAN+bKfDFAyO47phs5BbXbqW2tnbhwoU5OTldHQhpXvRZNTBBruGBXMMDuYYHcg0P5BoeyDU8kGt4INfwQK7hgVzDA7mGB3IND+QaHsg1PJBreCDX8ECu4YFcwwO5hgdyDQ/kGh7INTw80rW/P7kPVboJHum6qampq0Oggke69lCQa3gg1/BAruGBXMMDuYYHcg0P5BoeyDU8kGt4INfwQK7hgVzDA7mGB3IND4/5lvTtt99Wq9UYhpnN5tbWVrlczmAwDAbDqVOnujq058VjyvX06dNbW1vr6uqam5ttNlt9fX1dXR2T6a61dN2Bx7hOTk4ODQ198ojdbh86dGjXRUQaj3ENAEhNTX1yKSx/f/9Zs2Z1aUTk8CTXycnJwcG/LMM4dOjQ9oWwPQJPcu14QjqKdkBAgGcVas9zPWnSJEfRHj58uGN1Wg/i2YsFWUy21gazXuvGla9JMfn1eSdOnBg5aHplmVtW0SULAwCRH+4r83rmDpbPaF+fP9h8v0jL98a5Ao9fwslNcEXMpiojh4/1HyLqO7izxSE7c318R4NvAKf/0Bdlh0ZXsNns5/Y3Rsby+w/pUHeHrvN+aPLxZ/cZ9OLuZ0eBM3sb+iQKogc6X5jS+bOxqcZoNNiQaLIMmyQrvajqqPg6d61oMHe05DKiE9hcprLF0tEOGs6F6tRWHwnpNYcRAAD/Xlx1i/OdYZy7thGAsHpG/193w6C1AuC88YcqCngg1/BAruGBXMMDuYYHcg0P5BoeyDU8kGt4INfwQK7h4XbX02aM2/7t1+6+iyt8uemL2e9Oh3CjblquP0lf8Z/juV0dBc10U9c//3y7q0OgH9pGbAmC2Lf/h++zswAA/frG/uGdebGx8Y/vgbMOHtq7ZeuXXl5eMTHxK1eke4u8AQAPHlQcPrL/xs3Cxsb6sNCI8eMnJ0+aCgB4bXQiAGBDxqebt/zjSO7ZTm76SfoKBoMxZvS4L/621mDQ9+sX+97cJX37Pt4OJXvX9pOnjra0PJLJ5PFxCUvTVmIYBgDQ6/Xr1n9882ZheHhU8sSpT15QoWj9ZvPfy24VG43GQYOG/n7mH0NCQju4OWloK9dZ2zJzc/elf5Lx8ap1Uqn/RysXPXxY5Ug6d/4nnU771y8yP/zgL2VlRTt2bHYc//qbjYWFl5Ys/uiL9V+NHz9501d/vXwlHwBw4j/5AIAPP1jduWgAAI7jt26X5P30ny2bdx0/dpHtxV7/1zWOpB07t+Tk/jh/Xtr+fSffnbPg7Lm8fft/cCRlbPy0tvZhxobNn36S8aCq4vKVi47jBEEsXTavqPj60rRV323f6+sjXvD+O3X1tXQpoqdcq9SqH/ftTluyYlDiEABAUtIrer2uVdHSq1cYAIDH48+a+a7jzPyCcyWlNx1/X716vV6vC5AHAgBejk88ceLw1cKCIUmvkLq1Qa//8IO/8Hg8AMDoUW9+8be1er2esBH/3vP9/PeWDh/+KgDg1ZFjKivv7f7h2ykpqSqV8szZvI+Wr+nXNwYAMG/u4oJLjzf+Li0teviwamPG5oEvDwIAzH8vLb/g3IED/1q8aDktluhxXfWgAgDQp0//xxfF8fRPNrSnxsbEt//dW+RjNpke/2C3Hzy458rV/JqaaseBgIAgsrcO6RXmEA0AEAiEAACNRt2qaLFYLO2VCQAgOrqvVqutq6vRaNQAgNDQiPak3r373bt3BwBQWlbEYrEcoh1bk8bHJRSX3CAbUkfQ41qr1QAAOGznW9A6tt520L65rc1mW7FqicVi/tMfF8bHJwoFwkVL3qVwa0cV/BQKRctT8XC5PACAwaBXqZUAAB6X90sSh9v+r7BYLI6nRTs+PrRNj6HHNZ8vAADo9SQmfd29d+fOnVsZG75JGDjYcUSr1UglMhrjMRgN7UccsYnFEqvVCgAwmoxPJQEA/PwkXC533Wf/ePJSTIy26fT0PBujonrjON7+62a321esWnLy5NFOsqhUSgBAu9yqqsqqqkpaggEAREZGM5nMW7eK24+Ul5cJBUKpVCaXBwIAysoeJ1kslmvXr7TnMhgMMpn85fhExx9//4CoqN50RUWPa4FAMHbM+NzcfcdPHL5ZdC3znxuuX7/yZHX5a8JCI3Ac3/vjLrVG/fBhVeY/NwxKHNLY1AAAYLPZUqns2rXLN4uuOYohWURC0dgx43f/8F1BwXm1Rn3q1LFDOXunTn0bwzCpVBYTE7dz55aammqTyfTZuj+3V2sJAwcPHjwsI+PTpqZGlUqZk7vvvfmzTpw4TNXK09DWvl6y+KMvN32x8e/rCIKIioxOX7vB0QjpCH9/+Z9XffZ9dlby5FFBQSF/Xvlpq6Jl9V8+eGf21O937H/7d3N27NxytbDg3/86KhRQ2Uv4/QXLMAz7dN0qq9UaGBj8u7dmv5X6jiNp5Yr0L79cP/e9ty0Wy5tvTBw/Lvli/uPG5fp1Xx4+ciD9s5W3b5eGhISOGTNuypRUSj6c4Hw+39WTCrMRxL3qfAd0RCec2FE7fJIkIMJJM6GbvqP3SLr7rOqJk17tKOmjj9YOf6XD1G5Id3edlfWvjpJ8fTysiuvurh1v8D0DVF/DA7mGB3IND+QaHsg1PJBreCDX8ECu4YFcw8P5eyOHx7QRNujB9AQEPiwmy3mS83LtLcEbqgxOkxCdU1mikQSxnSY5dx38Es9s6C6LWHgQjVWG6AQhhpH5vpGJM5LeFJ/KrnNzbD0Ko544f6DxtWnSjk7obE2LugrDyezG+JFiH382Wj+kIzAMKJvNmjbLzdOtv/84lM3tcNz9GWu1aJXWG6fbGquMhg6+Z4eP3W43Wyxsr+7yubxI6sVg2IOjuIljn9Gf7jHrTrZTW1u7cOHCnJycrg6ENKh9DQ/kGh7INTyQa3gg1/BAruGBXMMDuYYHcg0P5BoeyDU8kGt4INfwQK7hgVzDA7mGB3IND+QaHsg1PJBreCDX8ECu4YFcw8MjXUdGRnZ1CFTwSNcVFRVdHQIVPNK1h4JcwwO5hgdyDQ/kGh7INTyQa3gg1/BAruGBXMMDuYYHcg0P5BoeyDU8kGt4eMy3pPPmzdPr9QwGw2g0VldXR0dHMxgMk8m0d+/erg7tefGYr8wTExO3bt3a/mN5eTkAQCajZx14OHhMHfLWW28FBwc/ecRut8fHx3eco9vhMa4FAsHEiRPb12AHAAQEBKSm0rYQOAQ8xjUAYMaMGUFBv2yKEhsbO2DAgC6NiBye5FogEEyYMMGxg4pMJvOsQu1hrgEAqampISEhAIA+ffrExcV1dTjkgNEOIax2vcYKgPNVkEjCeXNMyqFDh2b8zx80bVS26Pg1TCaDJ6JtE5lOcFf7uuq2rrJEp3hkaa03EVabrBdP1WJ2x41ch8NjtjWZ2DxmQARXEsCKiOHLejnfAMpFaHZttdguHm4py1f7yrlcHx5fzMW9MCYLRqlxEauJsJitula9rlXP4WN9BwkGDPeh9xZ0ur58XHHj/9rk0b6+waInG2ceh8VsbatWalr0I1IkL71MZXcbp9DjmiDA7vUP+WKeJJy2ncq6HIvRqqxXCYXgzd/T83ZKg2ud2rpjTVXk0ECu0Pl6ix6Nsk5t1uimLw1+jnOfgauutUpLblZTYIzcoyuNztG26q1a7eT3Aly8jqvt6+/TqwP792TRAACBHw8X8HM317t4HZdc78moiRwSyOhg+dCehMCPb8O9Co60uHIR6q6v/aRgcjmcnlhHO8U32Pdekb65zvQc5zqHomu73X75mEIa4WG7RLmIOMz3wiHqRZui64KjrUF9XyzRAAChhGc0gJp7emrZKbouvagWyWlr5NPOhsy3Dhz5mzuuzJcISs6rqeWl4rquwsD39mKyPKyPkBaEUl51OYktnJ+Eiq/KEi3Xl/ccJ/ZAMCYmkrBr7lKpRqj0qTbXm3l+NPfLtEMQ1uM/bSm/m69UNoaHxg1Lmtav9yuOpDXr33hj9FydXnnq9Ha2F7f3S0OSx/2vSCQBADQ+qtxzIL2p+UFURMKYkXPcFJsDjg/30UNjSDTp0kalXKuaLbjbuu4OHc24cOnfw5OmrVqWE9t/VPaeFSVlpx1JTCbr7MXdDAaWvvLU8sU/PqguPnlmGwDAarVsz07z8ZYtX7z3t68vPHtxt0bjUkO4cxgYplJQ6Tqn4tqgJXC2W1xbLKZrRcdG/eadoYOn8HneSQmTXh7wRt7Zb9tPkIiDx4yczeUKRSJJ76ghtXV3AAClt88oVU2Txi319ZHLZREpEz4wGDXuCM8Bi83UtlFZ5Z60a7PRJg7gYEy3PBhr6sutVnN0VFL7kciwgQ1N93V6lePH4KC+7Ulcrsho0gIAWlprvFgcse/j/gqRUOLj7e+O8BzgbCaTReVVmXR97cXB2hqNst42d+g2GrQAgK+3z33quEbbyud5AwCcDqTpDWov9n/VnizcLQMrDixGgmGl0mFH5dnI4TMtJoLNo9+140E3NXmlRBzy5HFfb3knuXhckcn0Xw0Do4lis+x5sJoIXx8q3qjkEcvZhJkAvA62YnIBqV8vFosNAIiKSHAc0WgVdrudze7soe/rE2CxGBua7gf4RwEA6hruqjXNtMfWjo2w+UipPK6olE1JEEvXZqSQ8Zmw2bzXX/tT3plvK6uLLFZzSdnprJ2LDh59xhtg/74jcNxrX856s9moUjfv/vFj3uMKxy3o2/TyUC6FjFTKdWSs4H5xMwh3SxP7td/MCgyIPnMh+15FIYcjCAuJnZa8qvMsXI7g3Zl/P3bqnx+vG+XF4vz29YU3Sk66qZ+XsNgMaktgJBXXFMdlslZVRiQF414eMEBOL8p6LZtpHPcHKu0cis+3AcO922opdsF4NKoG9cuvUaygKM57GjLe78YHFX6h3h21/LbuXFhTV/7r4zYbYbfbmUzn912RdkDAp61qOn3++9MXsjtIZADg/Bf6fxfsbm+qP4W6Secrw+WhFBuU1Md2i88rfy4yy17ycx6WpsVqdT7RyWwxebGcj+aIfQOpBeMUg0HT0QukTq/m80ROk7xFso6KwoPC2uR5crE/xaEol8bR922q40m8+WIqDwqPo7lCEdYbHzSW+gQYl95Hpi0Jqit7ZDV3ly3w3IeyXsPnE66IpmF+iNlo2/dVvX9vWQ9ukyjq1HyO5Y2Zrs5+cvU924uDTVscWHmlVqfomfvztla34YTBddF0zp3cv6mOALg0QozhPWRszKA2aZo0wRH4sAnOn/9koXOeatE55aWjrZIwb98gkZs6uOFg1Jpbq5V2i2XEFEmv3rSN9tE/1/3KCUXJBRWLg/PEPL4fB2cxWWymm/q76YKwEBYTYTXbtC06bYteLPeKHSakcTawA3d9V9BUbawo0TXXmxQNZqOOEAdy2pqozxhyKxw+btJZuQKmfyhXHuoVHsMXienvwoT3jbTZaOu232IzmQzcC8aURI/5Hr0H0K2r0R4Gcg0P5BoeyDU8kGt4INfw+H8i7F7FqGjFXAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x00000110EA41BD70>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e294028",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Checkpointer requires one or more of the following 'configurable' keys: []",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m initial_state = {\n\u001b[32m      2\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m'\u001b[39m : [HumanMessage(content = \u001b[33m'\u001b[39m\u001b[33mWhat is the Capitial of india\u001b[39m\u001b[33m'\u001b[39m)]\n\u001b[32m      3\u001b[39m }\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mchatbot\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m)\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m'\u001b[39m][-\u001b[32m1\u001b[39m].content\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\MY_Folder\\Git_Folders\\LANGGRAPH-UDEMY\\U_agentic_ai\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2719\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[39m\n\u001b[32m   2716\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]] = []\n\u001b[32m   2717\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2719\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2720\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2721\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2722\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2723\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2724\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2725\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2726\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2727\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2728\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2729\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2730\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2731\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2732\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2733\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mints\u001b[49m\u001b[43m \u001b[49m\u001b[43m:=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINTERRUPT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m   2734\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\MY_Folder\\Git_Folders\\LANGGRAPH-UDEMY\\U_agentic_ai\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2343\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2326\u001b[39m run_manager = callback_manager.on_chain_start(\n\u001b[32m   2327\u001b[39m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   2328\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   2329\u001b[39m     name=config.get(\u001b[33m\"\u001b[39m\u001b[33mrun_name\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.get_name()),\n\u001b[32m   2330\u001b[39m     run_id=config.get(\u001b[33m\"\u001b[39m\u001b[33mrun_id\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   2331\u001b[39m )\n\u001b[32m   2332\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   2333\u001b[39m     \u001b[38;5;66;03m# assign defaults\u001b[39;00m\n\u001b[32m   2334\u001b[39m     (\n\u001b[32m   2335\u001b[39m         debug,\n\u001b[32m   2336\u001b[39m         stream_modes,\n\u001b[32m   2337\u001b[39m         output_keys,\n\u001b[32m   2338\u001b[39m         interrupt_before_,\n\u001b[32m   2339\u001b[39m         interrupt_after_,\n\u001b[32m   2340\u001b[39m         checkpointer,\n\u001b[32m   2341\u001b[39m         store,\n\u001b[32m   2342\u001b[39m         cache,\n\u001b[32m-> \u001b[39m\u001b[32m2343\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_defaults\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2344\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2345\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2346\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2347\u001b[39m \u001b[43m        \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2348\u001b[39m \u001b[43m        \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2349\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2350\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2351\u001b[39m     \u001b[38;5;66;03m# set up subgraph checkpointing\u001b[39;00m\n\u001b[32m   2352\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.checkpointer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\MY_Folder\\Git_Folders\\LANGGRAPH-UDEMY\\U_agentic_ai\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2234\u001b[39m, in \u001b[36mPregel._defaults\u001b[39m\u001b[34m(self, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug)\u001b[39m\n\u001b[32m   2232\u001b[39m     checkpointer = \u001b[38;5;28mself\u001b[39m.checkpointer\n\u001b[32m   2233\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m checkpointer \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config.get(CONF):\n\u001b[32m-> \u001b[39m\u001b[32m2234\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2235\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCheckpointer requires one or more of the following \u001b[39m\u001b[33m'\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m'\u001b[39m\u001b[33m keys: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m[s.id\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39ms\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mcheckpointer.config_specs]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   2236\u001b[39m     )\n\u001b[32m   2237\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m CONFIG_KEY_STORE \u001b[38;5;129;01min\u001b[39;00m config.get(CONF, {}):\n\u001b[32m   2238\u001b[39m     store: BaseStore | \u001b[38;5;28;01mNone\u001b[39;00m = config[CONF][CONFIG_KEY_STORE]\n",
      "\u001b[31mValueError\u001b[39m: Checkpointer requires one or more of the following 'configurable' keys: []"
     ]
    }
   ],
   "source": [
    "initial_state = {\n",
    "    'messages' : [HumanMessage(content = 'What is the Capitial of india')]\n",
    "}\n",
    "\n",
    "chatbot.invoke(initial_state)['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d64371e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Hello RAM! It's nice to meet you. How can I assist you today?\n",
      "AI: Sure, 125 + 10 equals 135.\n",
      "AI: (10 * 12) + 3 equals 123.\n"
     ]
    }
   ],
   "source": [
    "thread_id  = '1'\n",
    "\n",
    "while True:\n",
    "    user_query = input('TypeHere: ')\n",
    "\n",
    "    if user_query.strip().lower() in ['exit','quit','bye']:\n",
    "        break\n",
    "\n",
    "    config = {'configurable':{'thread_id':thread_id}}\n",
    "\n",
    "    response = chatbot.invoke({\n",
    "    'messages' : [HumanMessage(content = user_query)]\n",
    "        },config = config)\n",
    "\n",
    "    print('AI:',response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9fb1e28d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='hi my name is RAM', additional_kwargs={}, response_metadata={}, id='edcfc240-3109-402b-901b-e662beefbfdc'), AIMessage(content=\"Hello RAM! It's nice to meet you. How can I assist you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 12, 'total_tokens': 29, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BxTjPZVg9JXxoXJNzJAMGDG8PN5tp', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--7a40ae6e-a742-4378-95ca-9b05b8f00176-0', usage_metadata={'input_tokens': 12, 'output_tokens': 17, 'total_tokens': 29, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='add 10 to 125', additional_kwargs={}, response_metadata={}, id='7e1b4a74-aa14-4dc6-8827-f901dfa61118'), AIMessage(content='Sure, 125 + 10 equals 135.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 43, 'total_tokens': 54, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BxTjWzcjLtfM1OpTnfORlxeZyfFur', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--d56c02c8-8a8e-4560-9c7d-18f7641a7d25-0', usage_metadata={'input_tokens': 43, 'output_tokens': 11, 'total_tokens': 54, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='what is (10 * 12) + 3?', additional_kwargs={}, response_metadata={}, id='4bc48b1b-f545-41ff-a30b-adeb681f90c9'), AIMessage(content='(10 * 12) + 3 equals 123.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 74, 'total_tokens': 87, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BxTjilZszkt5o7awz9rKUSdNzyhhK', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--fef18e02-e4fc-46d3-875b-a52d4745de10-0', usage_metadata={'input_tokens': 74, 'output_tokens': 13, 'total_tokens': 87, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f069f32-d30c-6fed-8007-2fe0d2739641'}}, metadata={'source': 'loop', 'writes': {'chat_node': {'messages': [AIMessage(content='(10 * 12) + 3 equals 123.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 74, 'total_tokens': 87, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BxTjilZszkt5o7awz9rKUSdNzyhhK', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--fef18e02-e4fc-46d3-875b-a52d4745de10-0', usage_metadata={'input_tokens': 74, 'output_tokens': 13, 'total_tokens': 87, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}, 'step': 7, 'parents': {}, 'thread_id': '1'}, created_at='2025-07-26T07:36:00.462846+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f069f32-c214-63d3-8006-bf8fb4a93d05'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.get_state(config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de284c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c482fc82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3417d21b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba559e00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1209baf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d11f947",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "U_agentic_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
